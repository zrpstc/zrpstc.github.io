## Finding a Protein Motif 寻找蛋白基序

## 相关介绍
- 本题要求找N-糖基化的motif在蛋白质序列中的位置。

- Motif是指具有特定结构和功能的一段氨基酸序列。

- 题目中所给的查询蛋白质序列及相关信息的网站UniProt。UniProt 是 Universal Protein 的英文缩写，是信息最丰富、资源最广的蛋白质数据库，uniprot_id  即蛋白质在该数据库中的id，页面可以通过 http://www.uniprot.org/uniprot/uniprot_id 进行浏览， fasta格式的蛋白质序列通过 http://www.uniprot.org/uniprot/uniprot_id.fasta 获取。

## 问题描述
给定最多15个蛋白质的uniprot_id，返回包含N-glycosylation motif的uniprot_id和找到的motif的所有起始位置

## 个人答案

由于没有仔细阅读，并且对于蛋白质基序识别相关问题的缺乏了解，所以没有注意到题目中要求查询特定蛋白质序列的fasta文件提取基序，而是导出了相关蛋白质信息的json文件进行解析，由此得到的基序信息会缺失而且不是常用的流程。
个人代码如下：

```

import json
import urllib.request
import jsonpath

IDs = []
data = []
##首先处理输入的Access_ID
##Uniprot网站改变了ID规则，例如“P07204_TRBM_HUMAN”只需要保留P07204去查询即可，
##否则显示没有结果
def getstr():

    ##读取txt文件中的带查询Prot的ID
    with open('rosalind_mprt.txt', 'r') as f:
        ##读取到list列表
        for line in f:
            data.append(list(line.strip('\n').split(',')))

        ##读取txt文件中的所有行包括换行符
        #data = f.readlines()

    # inputs = []
    # for line in data:
    #     inputs.append(line.strip())

    for i in data:
        IDs.append(i[0].split('_')[0])
    #print(IDs)
    #print(data)
    f.close()
    return IDs



##通过API获取json文件
def getJsonFile(str):
    #构建API请求url
    url = f'https://rest.uniprot.org/uniprotkb/{str}.json'

    #发送API请求并获得响应
    response = urllib.request.urlopen(url)

    #读取响应数据
    jsonfile = response.read().decode('utf-8')
    ##将数据保存在本地json文件中
    jsonpath = './{}.json'.format(str)
    with open(jsonpath, 'w') as file:
        json.dump(jsonfile, file)
    #print(jsonfile)
    return jsonpath


##解析json文件获取location
def getLocationMotify(jsonstr):
    with open(jsonstr, 'r', encoding='utf-8') as file:
        d = json.load(file)
    #print(data)
    ##把json对象转为dict
    dict = json.loads(s=d)
    # features嵌套在最外层的json数据中，是一个列表
    fea = dict['features']
    #print(fea)
    #fea = jsonpath.jsonpath(data, "$.features.*")

    locations = []
    for f in fea:
        #print(f['description'])
        if f['description'] == 'N-linked (GlcNAc...) asparagine':
            #print(f['location']['start']['value'])
            locations.append(f['location']['start']['value'])
    result = " ".join(str(i) for i in locations)
    return result




sequences = getstr()
#print(sequences)
for seq in sequences:
    if getLocationMotify(getJsonFile(seq)) != "":
        for s in data:
            if seq in s[0]:
                print(s[0])
        print(getLocationMotify(getJsonFile(seq)))




## "description": "N-linked (GlcNAc...) asparagine"


```


## 推荐解答

蛋白基序的表示方法：```[XY]```意为X或Y，```{X}```意为除了X以外任意一种氨基酸。

N-糖基化基序可表示为```N{P}[ST]{P}```，解析符合该特征的基序字符使用正则表达式。

**正则表达式**（Regular Expression，在代码中常简写为regex、regexp或RE）是计算机科学的一个概念。正则表达式通常被用来检索、替换那些符合某个模式(规则)的文本。即用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。


```
import urllib.request
import re

data = []
names = []
with open('rosalind_mprt.txt', 'r') as f:
    for line in f:
        data.append(list(line.strip('\n').split(',')))

for i in data:
    names.append(i[0].split('_')[0])
f.close()

i = 0
while i < len(names):
    full_name = data[i][0]
    name = str(names[i]).strip()
    url = 'https://rest.uniprot.org/uniprotkb/' + name + '.fasta'
    req = urllib.request.Request(url)
    response = urllib.request.urlopen(req)
    the_page = response.read()
    start = the_page.find('\nM'.encode())
    the_page = str(the_page)
    seq = the_page[start + 2:].replace('\\n', '').replace('\'', '')
    seq = ' ' + seq
    regex = re.compile(r'N(?=[^P][ST][^P])')
    out = []
    index = 0
    while index < len(seq):
        index += 1
        if re.search(regex, seq[index:]) == None:
            break
        if re.match(regex, seq[index:]) != None:
            out.append(index)
    if out != []:
        print(full_name)
        print(' '.join([str(i) for i in out]))
    i += 1

```

## 拓展思考
本题对于字符串的匹配涉及到重叠（Overlap）区域的问题。

例如匹配字符串test：```testest```应该输出两个实例```["test","test"]```
但是正则表达式是贪婪模式的，它们消耗尽可能多的目标字符串。 一旦消耗掉字符，就不会再次检查它，因此找不到重叠的字符串。

解决这一问题，Python的标准库re提供了以下表达格式：

正向预查
: 
```(?=…)```
Matches if ... matches next, but doesn’t consume any of the string. This is called a lookahead assertion. For example, Isaac (?=Asimov) will match 'Isaac ' only if it’s followed by 'Asimov'.

正向否定预查
: ```(?!…)```
Matches if ... doesn’t match next. This is a negative lookahead assertion. For example, Isaac (?!Asimov) will match 'Isaac ' only if it’s not followed by 'Asimov'.

示例代码：

```
import re
regx = re.compile("(?=(test))")
print(regx.findall("testest"))

>>> ['test', 'test']
```
```
import re
regx = re.compile('t(?=est)')
print([m.start() for m in regx.finditer('testest')])

>>> [0,3]
```

常用正则字符：

|正则字符  |描述  |
|--|--|
|\  |将下一个字符标记为一个特殊字符、或一个原义字符、或一个向后引用、或一个八进制转义符。例如，“n"匹配字符"n"。"\n"匹配一个换行符。串行"\\"匹配"\"而"\("则匹配"("。  |
| ^ |匹配输入字符串的开始位置。如果设置了RegExp对象的Multiline属性，^也匹配“\n"或"\r"之后的位置。  |
|$  |匹配输入字符串的结束位置。如果设置了RegExp对象的Multiline属性，$也匹配“\n"或"\r"之前的位置。  |
| \* | 匹配前面的子表达式零次或多次。例如，zo\*能匹配“z"以及"zoo"。\*等价于{0,}。 |
| + | 匹配前面的子表达式一次或多次。例如，“zo+"能匹配"zo"以及"zoo"，但不能匹配"z"。+等价于{1,}。 |
| ? | 匹配前面的子表达式零次或一次。例如，“do(es)?"可以匹配"does"或"does"中的"do"。?等价于{0,1}。 |
| . |匹配除“\n"之外的任何单个字符。要匹配包括"\n"在内的任何字符，请使用像"(.\|\n)"的模式。  |
|{n}  | n是一个非负整数。匹配确定的n次。例如，“o{2}"不能匹配"Bob"中的"o"，但是能匹配"food"中的两个o。 |
|{n,} |n是一个非负整数。至少匹配n次。例如，“o{2,}"不能匹配"Bob"中的"o"，但能匹配"foooood"中的所有o。"o{1,}"等价于"o+"。"o{0,}"则等价于"o\*"。 |
|{n,m} |m和n均为非负整数，其中n<=m。最少匹配n次且最多匹配m次。例如，“o{1,3}"将匹配"fooooood"中的前三个o。"o{0,1}"等价于"o?"。请注意在逗号和两个数之间不能有空格。 |
|x\|y |匹配x或y。例如，“z\|food"能匹配"z"或"food"。"(z\|f)ood"则匹配"zood"或"food"。 |
|[xyz] |字符集合。匹配所包含的任意一个字符。例如，“[abc]"可以匹配"plain"中的"a"。 |
|[^xyz] |负值字符集合。匹配未包含的任意字符。例如，“[^abc]"可以匹配"plain"中的"p"。 |
|[a-z] | 字符范围。匹配指定范围内的任意字符。例如，“[a-z]"可以匹配"a"到"z"范围内的任意小写字母字符。|
|[^a-z] |负值字符范围。匹配任何不在指定范围内的任意字符。例如，“[^a-z]"可以匹配任何不在"a"到"z"范围内的任意字符。 |
